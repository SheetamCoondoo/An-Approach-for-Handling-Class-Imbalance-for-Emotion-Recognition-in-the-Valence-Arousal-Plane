# Methodology

The proposed work is executed in a sequence of steps as discussed below:

---

## 1. Loading and Preprocessing the Dataset

- The process begins by importing a dataset from a given CSV file.
- The script displays the class distribution from the `Label` column, highlighting the imbalances present in the dataset.

---

## 2. Data Normalization

- After loading the dataset, the feature set is normalized using **MinMaxScaler**.
- This scales all features to a range of 0 to 1, ensuring that no single feature disproportionately affects the model's performance.

---

## 3. Using the CTGAN Model

**CTGAN (Conditional Generative Adversarial Network)** is employed to handle tabular data and generate synthetic data conditioned on categorical features. The CTGAN model consists of two main components:

### a. Generator Component

#### i. Input Layer:

- **Noise Vector**: Provides randomness for generating diverse synthetic data instances.
- **Conditional Vector**: Encodes information about specific categories on which the synthetic data needs to be conditioned.


#### ii. Hidden Layers:

- Fully connected or dense layers transform concatenated inputs (noise and conditions) through non-linear transformations.
- These layers help learn complex patterns present in the dataset.


#### iii. Output Layer:

- Produces output that emulates the structure of real tabular data, matching the number of features in the dataset.
- The generated data is passed to the discriminator for evaluation.

---

### b. Discriminator Component

#### i. Input Layer:

- **Synthetic vs Real Data**: Receives either synthetic data generated by the generator or actual data from the dataset.
- **Conditional Vector**: Processes conditioned data to evaluate accuracy more efficiently based on specific categories.


#### ii. Hidden Layers:

- Distinguishes real data from fake data, conditioned on categorical information used by the generator.
- Analyzes input data and identifies patterns that differentiate real data from synthetic data, improving accuracy over training iterations.


#### iii. Output Layer:

- A single neuron with a sigmoid activation function outputs a probability between 0 and 1:
    - Probability closer to **1** indicates real data.
    - Probability closer to **0** indicates fake data.

---

### Training Process

#### Adversarial Training:

- The generator and discriminator are trained simultaneously using a game-theoretic approach.
- The generator aims to produce realistic synthetic data, while the discriminator improves its ability to distinguish between real and fake data.
- Training continues until the discriminator can no longer differentiate between real and fake data effectively.


#### Conditioning:

- Ensures that synthetic data is relevant to specific classes within the dataset.

---

## 4. Combining, Saving Augmented Dataset, and Reporting Class Distribution

- The newly generated dataset is concatenated with the original dataset.
- The augmented dataset is saved in CSV format to a specified folder.
- The final class distribution is printed to verify whether classes are balanced.

This process addresses class imbalance in datasets, which is crucial for training unbiased machine learning models by generating synthetic data using the CTGAN model.

---

## Summary

This methodology ensures effective handling of class imbalance through synthetic sample generation using CTGAN while maintaining relevance to specific classes in the dataset. It provides a robust foundation for training machine learning models with balanced datasets.

